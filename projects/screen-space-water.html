<!DOCTYPE HTML>

<html>
	<head>
		<title>Screen Space Water Rendering - Jonathan Kump</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
							<header id="header">
								<div class="logo"><strong>Water Rendering Project</strong> - Jonathan Kump</div>
								<ul class="icons">
									<li><a href="https://github.com/jlkump" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
									<li><a href="../contact.html" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
									<li><a href="https://www.artstation.com/landon_k" class="icon brands fa-artstation"><span class="label">Artstation</span></a></li>
									<li><a href="https://medium.com/@landon2002" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
								</ul>
							</header>

							<!-- Content -->
								<section>
									<h1>Screen-Space Water Rendering</h1>
									<hr class="major" />

                                    <h2>Overview</h2>
									<p>
										The goal of this project was to explore water simulations and water
										rendering using the OpenGL API and C++. For this, I gathered
										papers and online articles on the subject, primarily drawing from
										the GDC 2010 talk slides titled 
										<a href="#ref-water-rendering">
											<em>Screen Space Fluid Rendering for Games</em>
										</a> 
										by Simon Green at NVIDIA. I also drew upon Ten Minute Physics' 
										<a href="https://youtu.be/XmzBREkK8kY?si=8lUgJCES6hdRJI9I">
											YouTube video 
										</a>
										for the physical simulation of particles, which I will cover in a different walkthrough.
                                    </p>
									<p>
										Everything is done essentially from scratch, save for an OpenGL CMake build template
										I used as a basis for building the project. The template comes from Tomasz Galaj's
										OpenGL CMake tutorial <a href="#ref-cmake">
										<em>How to setup OpenGL project with CMake</em></a> (the tutorial no longer seems to be available sadly).
									</p>
									<p>
										Below is a video showcase of my progress throughout the development of the water renderer.
										After that, I have a walkthrough of my process for development. Here is the 
										<a class="icon brands fa-github" href="https://github.com/jlkump/opengl-waterflow">Github link</a> for the project.
									</p>
									<hr class="major" />

                                    <h2>Video Showcase</h2>
									<iframe width="100%" height="600" src="https://www.youtube.com/embed/MIAm_noXHIc?si=7t0uoWxlvioESILt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
									<hr class="major" />

                                    <h2>Process</h2>
									<p>
										With any simulation, it is important to think about the representation
										for the object of simulation.
										Water in real life is a continous form that changes
										shape and can split off from the larger form in a spray. In any
										computer simulation, computing over continous regions is very
										expensive, involving integrations over some function of shape.
										In order to get a fast implementation, we can instead discretize
										over some region.
										Thus, for water simulation, there are two main approaches 
										called Eularian and Lagrangian based simulation, which are
										essentially just fancy names for grid-based and particle-based
										simulation respectively.
                                    </p>
									<div class="row gtr-50 gtr-uniform">
										<div class="col-8">
											<iframe width="100%" height="400" src="https://www.youtube.com/embed/C9DtT2yXxME?si=zkBnAVGGioiMIn-I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
										</div>
										<div class="col-4">
											<p>
												I started by creating a 2D visualizatoin of diffusion using a Eularian grid-based
												simulation, both to get familiar with water physics and to get familiar
												with OpenGL's compute shaders. You can see a short video demonstration to the left.
											</p>
											<p>
												Since this was used to mainly get familiar with compute shaders and
												setup the project with OpenGL (and also because I was eager to do a
												3d-based rendering) I quickly moved on to the 3d rendering and simulation.
											</p>
										</div>
									</div>
									<p>
										A Eularian-based simulation is somewhat difficult to visualize in 3D, especially
										for a realistic rendering, so instead, using a Lagrangian particle-based representation
										makes things much easier. For the actual simulation, the representation uses a mix
										of Eularian and Lagrangian which makes the simulation more efficient and more accurate,
										while the rendering just considers the particle-based representation
									</p>
									<blockquote>
										The technique used for simulation is called PIC/FLIP and is discussed in <a href="#ref-sand-as-fluid"><em>Animating Sand as a Fluid</em></a>.
									</blockquote>
									<p>
										A particle-based rendering technique is discussed by <a href="#ref-water-rendering">Simon Green's
										talk</a>, which, at a high level, involves taking particles, rendered as sprites, 
										and calculating their depth. This depth is rendered to texture and smoothed to create the
										appearance of a continous surface. Finally, the normals are extracted from the depth 
										texture and form the normals of the water itself. Having extracted the normals, we
										can perform traditional rendering techniques for shading, reflection, and 
										refraction.
									</p>
									<p>
										With that, in the following section I will cover my implementation of this high-level
										idea and any problems I encountered during my implementation. 
									</p>
									<h3>Implementation in OpenGL</h3>
									<p>
										There are four major steps in rendering the water. The first step is to render the particles
										as sprites with their depth rendered to texture. The second step is to perform a blend
										on the rendered texture. The third step is to extract normals from the blended depth texture.
										Lastly, we render the water using the Phong-illumination model.
									</p>

									<h3>Step 1 - Depth Texture</h3>
									<div class="row gtr-50 gtr-uniform">
										<div class="col-4">
											<span class="image fit"><img src="../images/waterflow/Depth-fix.png" alt="" /></span>

										</div>
										<div class="col-8">
											<p>
												In the first step, we need to render particle sprites at the positions of each particle. The
												positions are stored in a 2D texture for simulation on the GPU, so we take in the
												particle ids as UVs rather than positions in the rendering shader. I used GPU instancing
												for rendering the sprites since each particle renders the same 2D, screnn-space quad 
												just at different positions on the screen. Rendering the depth, we can see the result to the
												left with a rectangular section of water.
											</p>
											<blockquote>
												Instancing is a technique for rendering the same
												or very similar models many times without passing the same information across the bus to the
												GPU multiple times. A tutorial on how it is done can be found 
												<a href="https://www.opengl-tutorial.org/intermediate-tutorials/billboards-particles/particles-instancing/">here</a>.
											</blockquote>
										</div>
									</div>

									<br/>
									<h3>Step 2 - Blended Depth</h3>
									<div class="row gtr-50 gtr-uniform">
										<div class="col-3">
											<p>
												The next step blends the depth texture, producing a new blended texture. For this, I used
												a Gaussian blur, although the talk recommends a Bilateral filter to perserve in the water
												holes in the resulting depth texture. I found that my bilateral filter did not blend
												the depth texture enough however, as shown to the right. The changes in color are just
												due to differences in how I rendered the normal vector.
											</p>
										</div>
										<div class="col-3">
											<span class="image fit"><img src="../images/waterflow/waterflow-fixed-normals.png" alt="" /></span>
											<p>
												The normals as they are without blending, extracted directly from depth.
											</p>
										</div>
										<div class="col-3">
											<span class="image fit"><img src="../images/waterflow/blend-radius-10.png" alt="" /></span>
											<p>
												The normals blended with a Bilateral filter, producing artifacts.
											</p>
										</div>
										<div class="col-3">
											<span class="image fit"><img src="../images/waterflow/waterflow-documentation-blended-normals.png" alt="" /></span>
											<p>
												The normals blended with a Gaussian filter, properly blended with only artifacts at the edges.
											</p>
										</div>
									</div>
									<br/>

									<h3>Step 3 - Normal Extraction</h3>
									<p>
										The next step extracts the normals from the depth texture, the result of which you can see in the 
										pictures above. This step comes directly from Simon Green's talk and is the core of why it is
										an efficient screen-space rendering. Since we only consider the depth texture of a 2D rendering of
										water, we can quickly render an approximation of how the water should look if we extract the normals.
									</p>
									<p>
										The normals are extracted with the following steps:
										<ol>
											<li>
												Calculating the view-space position (the slides call it eye-space) of the 
												texel of water given the UV and depth. This is fairly straight-forward, simply
												taking the homogenous-space position from the UV and depth then multiplying by
												the inverse of the projection matrix. This is what it looks like in my shader:
												<pre>
<code>vec3 GetViewPos(vec2 tex_coord) {
	vec4 hs_pos = vec4 (
		2.0 * tex_coord.x - 1.0,
		2.0 * tex_coord.y - 1.0,
		2.0 * texture(depth_tex, tex_coord).r - 1.0,
		1.0);
	vec4 vs_pos = (inv_proj * hs_pos);
	return vs_pos.xyz / vs_pos.w;
}</code>
												</pre>
											</li>
											<li>
												We then calculate the view-space position of nearby points in positive and negative x and y.
												We do this to get vectors that are tangent to the surface of the water based on the depth texture.
												It is an approximation, but allows us to get a fairly realistic normal by cross producting
												these two tangent vectors. I discarded any normals that were pointing directly
												in the Z axis in order to keep the background of the scene clear,
												however, a much better approach would have been to use a stencil
												buffer to render to only sections of the screen with water.
												The code I used is as follows:
												<pre>
<code>vec3 GetNormal() {
	float depth = texture(depth_tex, uv).r;
	
	ivec2 texDimen = textureSize(depth_tex, 0);
	
	vec3 vs_pos = GetViewPos(uv);
	
	vec3 ddx = GetViewPos(uv + vec2(1, 0) / texDimen) - vs_pos;
	vec3 ddx2 = vs_pos - GetViewPos(uv + vec2(-1, 0) / texDimen);
	if (abs(ddx.z) > abs(ddx2.z)) {
		ddx = ddx2;
	}
	
	vec3 ddy = GetViewPos(uv + vec2(0, 1) / texDimen) - vs_pos;
	vec3 ddy2 = vs_pos - GetViewPos(uv + vec2(0, -1) / texDimen);
	if (abs(ddy.z) > abs(ddy2.z)) {
		ddy = ddy2;
	}
	vec3 norm = normalize(cross(ddx, ddy));
	if (norm.z + 1e-5 >= 1) discard;
	return norm;
}</code>
												</pre>
											</li>
										</ol>
									</p>

									<h3>Step 4 - Rendering</h3>
									<p>
										With the normal extracted, the last step is simply rendering the water using some
										illumination model. I used Phong illumination with a cube-map to sample for
										rendering reflections and refractions. The results at various different steps
										are shown below.
									</p>
									<div class="row gtr-50 gtr-uniform">
										<div class="col-3">
											<span class="image fit"><img src="../images/waterflow/Reflective-spheres.png" alt="" /></span>
											<p>
												Water rendered in full without blending the depth texture.
											</p>
										</div>
										<div class="col-3">
											<span class="image fit"><img src="../images/waterflow/Blended-reflections.png" alt="" /></span>
											<p>
												Water rendered blending with a small radius size for Gaussian.
											</p>
										</div>
										<div class="col-3">
											<span class="image fit"><img src="../images/waterflow/Blending-depth-18-slow.png" alt="" /></span>
											<p>
												Water rendering blending with a large radius size (18 texels) for Gaussian.
											</p>
										</div>
										<div class="col-3">
											<span class="image fit"><img src="../images/waterflow/watercube.png" alt="" /></span>
											<p>
												Water rendering on a cube of water with small particle size.
											</p>
										</div>
									</div>
									<br/>
									<h3>Cleanup</h3>
									<p>
										You'll notice in the pictures above, the water doesn't appear perfectly realistic. There
										are artifacts along the edges of the water and the particles are still fairly visible.
										There were two fixes I came up with for the artifact problem. 
										The first was to simply render the depth texture
										at lower resolution. We can do this because accuracy isn't as much a concern as getting the
										water to look realistic. This ended up having a pretty significant improvement, which you
										can see going from the left picture to the right picture below.
									</p>
									<div class="row gtr-50 gtr-uniform">
										<div class="col-6">
											<span class="image fit"><img src="../images/waterflow/smoothing-normals.png" alt="" /></span>
											<p>
												Rendering of normals as it was before with Guassian filter and a high resolution depth texture.
											</p>
										</div>
										<div class="col-6">
											<span class="image fit"><img src="../images/waterflow/smoothing-normals-improved.png" alt="" /></span>
											<p>
												Rendering with a lower resolution depth texture and Guassian filter. Much cleaner :)
											</p>
										</div>
									</div>
									<br/>
									<div class="row gtr-50 gtr-uniform">
										<div class="col-8">
											<p>
												The second fix, which solved the artifacts at the edge of the cube came when I examined the pictures
												above. The problem clearly came from blending, but the Gaussian filter was being applied properly.
												The actual problem was it was blending the background color
												of the image with the normals of the water. This was a fairly simply fix, simply ignoring any normals from
												the background which shouldn't be considered anyways. With that, you can see a big improvement to
												the render on the right.
											</p>
											<p>
												With that, we get a much nicer final render and all that's left is messing with the parameters
												for the illumination model to get a good looking effect. I messed with various appearances which you can see below.
											</p>
										</div>
										<div class="col-4">
											<span class="image fit"><img src="../images/waterflow/smoothing-normals-big-improvement.png" alt="" /></span>
										</div>
									</div>
									<div class="row gtr-50 gtr-uniform">
										<div class="col-6">
											<span class="image fit"><img src="../images/waterflow/water-messing-with-color.png" alt="" /></span>
										</div>
										<div class="col-6">
											<span class="image fit"><img src="../images/waterflow/final-color-choice.png" alt="" /></span>
										</div>
										<div class="col-6">
											<span class="image fit"><img src="../images/waterflow/Final-water-cube.png" alt="" /></span>
										</div>
										<div class="col-6">
											<span class="image fit"><img src="../images/waterflow/final-smoothing-appearance.png" alt="" /></span>
										</div>
										<div class="col-6">
											<span class="image fit"><img src="../images/waterflow/reflection-refraction-alt.png" alt="" /></span>
										</div>
										<div class="col-6">
											<span class="image fit"><img src="../images/waterflow/refraction-reflection-combined.png" alt="" /></span>
										</div>
									</div>

									<!-- For the Simulation Post -->
									<!-- <p>
										I have later found out, thanks to my class in concurrency, a spin-lock
										on the GPU is an awful idea (especially as the way I implemented it) due to
										the structure of a GPU. The GPU is broken up into Thread-blocks, warps, 
										and threads. Threads aren't exactly the same as they are on the CPU, since
										the GPU has SIMD processors, typically 32 lanes wide. The threads
										on a processor is called a warp and every thread in a warp executes in 
										lock-step. With a spin-lock, this could easily prevent the warp from
										progressing as a whole since a singular thread could hold the lock while
										the rest in the warp need to wait. The threads that need to wait will prevent
										the lock-holding thread from progressing. 
									</p>
									<p>
										Luckily, in my implementation, the only problem was poor utilization and poor
										performance since I acted at the scale of thread-blocks rather than on threads
										individually. With this, I had only really one thread per warp perfoming work,
										but it would prevent the lock-step problem. Without this, the screen would freeze
										up as the GPU would just spin (luckily most modern GPUs will just exit the program if it
										detects spining like this).
									</p> -->
									
									<!-- References -->
									<hr class="major" />
									<h2>References</h2>
									<div class="box">
										<ol>
											<li>
												<a id="ref-sand-as-fluid" href="https://www.cs.ubc.ca/~rbridson/docs/zhu-siggraph05-sandfluid.pdf">Yongning Zhu, Robert Bridson. <em>Animating Sand as a Fluid</em>, 01 July 2005.</a>
											</li>
											<br/>
											<li>
												<a id="ref-water-rendering" href="https://developer.download.nvidia.com/presentations/2010/gdc/Direct3D_Effects.pdf">Simon Green. <em>GDC 2010 - Screen Space Fluid Rendering for Games</em>, 9-13 March 2010.</a>
											</li>
											<br/>
											<li>
												<a id="ref-cmake" href="https://shot511.github.io/2018-05-29-how-to-setup-opengl-project-with-cmake/">Tomasz Galaj. <em>How to setup OpenGL project with CMake</em></a>
											</li>
										</ol>
									</div>

								</section>

						</div>
					</div>


				<!-- Sidebar -->
				<div id="sidebar">
					<div class="inner">
						<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a href="../index.html">Homepage</a></li>
									<li><a href="../artistic-portfolio.html">Artistic Portfolio</a></li>
									<li>
										<span class="opener">Code Projects</span>
										<ul>
											<li><a href="../projects/inverse-kinematics-godot.html"><strong>Inverse Kinematics</strong></a></li>
											<li><a href="../projects/screen-space-water.html"><strong>Screen-Space Water Rendering</strong></a></li>
											<li><a href="../projects/npr-brush-shader.html"><strong>NPR Brush Shader</strong></a></li>
											<li><a href="../code-projects.html">More</a></li>
										</ul>
									</li>
								</ul>
							</nav>

						<!-- Section -->
							<section>
								<header class="major">
									<h2>Recent Code Projects</h2>
								</header>
								<div class="mini-posts">
									<article>
										<h4>Inverse Kinematics</h4>
										<a href="inverse-kinematics-godot.html" class="image"><img src="../images/inverse-kinematics/ik-showcase-2.png" alt="" /></a>
										<p>
											Exploring Inverse Kinematics using the FABRIK method. 
											Made using GDExtension and C++.
										</p>
									</article>
									<article>
										<h4>Screen-Space Water Rendering</h4>
										<a href="screen-space-water.html" class="image"><img src="../images/waterflow/Final-water-cube.png" alt="" /></a>
										<p>
											Exploring a Screen-Space technique for rendering realistic water in real-time,
											covered in a 2010 GDC talk by Simon Green. Made using OpenGL and C++.
										</p>
									</article>
									<article>
										<h4>NPR Brush Shader</h4>
										<a href="npr-brush-shader.html" class="image"><img src="../images/npr-shader/Showcase.png" alt="" /></a>
										<p>
											Exploring NPR (Non-Photorealistic Rendering) techniques with
											a custom post process shader aiming to create the effect of 
											brushstrokes on a model in realtime. 
											Made using OpenGL and C++.
										</p>
									</article>
								</div>
							</section>

						<!-- Section -->
							<section>
								<header class="major">
									<h2>Get in touch</h2>
								</header>
								<p>
									If you would like to get in contact, please use the email below
									or message me through Linked-In. 
								</p>
								<ul class="contact">
									<li class="icon solid fa-envelope"><a href="lkump1@icloud.com">lkump1@icloud.com</a></li>
									<li class="icon brands fa-linkedin"><a href="https://www.linkedin.com/in/jonathan-kump-a73b7722b/">Jonathan Kump</a></li>
								</ul>
							</section>
					</div>
				</div>
				<!-- End of Sidebar -->

			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>